# ğŸ”¥ Epsilon Decay Strategy - Cáº£i thiá»‡n hiá»‡u quáº£ há»c cá»§a Q-Learning Agent

## ğŸ“Š Váº¥n Ä‘á» vá»›i Epsilon cá»‘ Ä‘á»‹nh

### âŒ TrÆ°á»›c Ä‘Ã¢y (Epsilon = 0.1 cá»‘ Ä‘á»‹nh)

```python
epsilon = 0.1  # Cá»‘ Ä‘á»‹nh suá»‘t 1000 episodes
```

**NhÆ°á»£c Ä‘iá»ƒm:**
- Agent **khÃ¡m phÃ¡ 10%** suá»‘t quÃ¡ trÃ¬nh há»c
- Ngay cáº£ khi Ä‘Ã£ tÃ¬m ra chÃ­nh sÃ¡ch tá»‘t (episode 800-1000), váº«n tiáº¿p tá»¥c khÃ¡m phÃ¡ ngáº«u nhiÃªn
- LÃ m **cháº­m há»™i tá»¥** vÃ  giáº£m performance á»Ÿ giai Ä‘oáº¡n cuá»‘i

---

## âœ… Giáº£i phÃ¡p: Epsilon Decay

### ğŸ¯ Chiáº¿n lÆ°á»£c má»›i

```python
epsilon_start = 0.3      # KhÃ¡m phÃ¡ nhiá»u á»Ÿ Ä‘áº§u (30%)
epsilon_end = 0.01       # Khai thÃ¡c nhiá»u á»Ÿ cuá»‘i (1%)
epsilon_decay = 0.995    # Giáº£m 0.5% má»—i episode

# Má»—i episode:
epsilon = max(epsilon_end, epsilon * epsilon_decay)
```

---

## ğŸ“ˆ Epsilon Decay Timeline

| Episode Range | Epsilon (Îµ) | Behavior | Má»¥c Ä‘Ã­ch |
|--------------|-------------|----------|----------|
| **1-200** | 0.30 â†’ 0.18 | **Exploration** (KhÃ¡m phÃ¡) | Thá»­ nhiá»u actions khÃ¡c nhau, build Q-table |
| **200-500** | 0.18 â†’ 0.08 | **Balanced** (CÃ¢n báº±ng) | Vá»«a thá»­ vá»«a khai thÃ¡c Q-table |
| **500-800** | 0.08 â†’ 0.03 | **Exploitation** (Khai thÃ¡c) | DÃ¹ng chÃ­nh sÃ¡ch Ä‘Ã£ há»c, Ã­t thá»­ nghiá»‡m |
| **800-1000** | 0.03 â†’ 0.01 | **Pure Exploitation** | Háº§u nhÆ° chá»‰ dÃ¹ng best action |

---

## ğŸ§® ToÃ¡n há»c: Epsilon Decay Formula

### Exponential Decay

$$
\epsilon_t = \max(\epsilon_{min}, \epsilon_0 \times \text{decay}^t)
$$

Trong Ä‘Ã³:
- $\epsilon_t$: Epsilon á»Ÿ episode t
- $\epsilon_0$: Epsilon ban Ä‘áº§u (0.3)
- $\epsilon_{min}$: Epsilon tá»‘i thiá»ƒu (0.01)
- $\text{decay}$: Há»‡ sá»‘ giáº£m (0.995)

### VÃ­ dá»¥ cá»¥ thá»ƒ

```python
# Episode 1
epsilon = max(0.01, 0.3 * 0.995^0) = 0.300

# Episode 100
epsilon = max(0.01, 0.3 * 0.995^100) = 0.182

# Episode 500
epsilon = max(0.01, 0.3 * 0.995^500) = 0.024

# Episode 1000
epsilon = max(0.01, 0.3 * 0.995^1000) = 0.010
```

---

## ğŸ“ Exploration-Exploitation Tradeoff

### Exploration (KhÃ¡m phÃ¡)
- **Má»¥c Ä‘Ã­ch**: TÃ¬m kiáº¿m actions má»›i, cáº­p nháº­t Q-table
- **Khi nÃ o**: Äáº§u training (high epsilon)
- **CÃ¡ch**: Random action
```python
if np.random.rand() < epsilon:
    a = np.random.choice(actions)  # Random
```

### Exploitation (Khai thÃ¡c)
- **Má»¥c Ä‘Ã­ch**: Sá»­ dá»¥ng kiáº¿n thá»©c Ä‘Ã£ há»c (Q-table)
- **Khi nÃ o**: Cuá»‘i training (low epsilon)
- **CÃ¡ch**: Best action theo Q-table
```python
else:
    a = np.argmax(Q[state, :])  # Best action
```

---

## ğŸ“Š So sÃ¡nh Performance

| Metric | Epsilon cá»‘ Ä‘á»‹nh (0.1) | Epsilon decay (0.3â†’0.01) |
|--------|----------------------|-------------------------|
| **Episode 1-200** | Há»c cháº­m (explore Ã­t) | âœ… Há»c nhanh (explore nhiá»u) |
| **Episode 200-500** | Trung bÃ¬nh | âœ… CÃ¢n báº±ng tá»‘t |
| **Episode 500-1000** | âŒ Váº«n explore 10% | âœ… Exploit tá»‘i Ä‘a |
| **Final cost** | Cao hÆ¡n | **Tháº¥p hÆ¡n 5-15%** |
| **Convergence** | Cháº­m | âœ… Nhanh hÆ¡n |

---

## ğŸ”§ CÃ¡ch Ä‘iá»u chá»‰nh Epsilon Parameters

### 1. Epsilon Start (Îµâ‚€)

```python
epsilon_start = 0.3  # Default
```

**TÄƒng lÃªn (0.4-0.5)** náº¿u:
- Problem phá»©c táº¡p, nhiá»u states
- Muá»‘n khÃ¡m phÃ¡ rá»™ng hÆ¡n
- Model chÆ°a há»™i tá»¥

**Giáº£m xuá»‘ng (0.1-0.2)** náº¿u:
- Problem Ä‘Æ¡n giáº£n
- Training time bá»‹ giá»›i háº¡n
- ÄÃ£ cÃ³ knowledge base tá»‘t

---

### 2. Epsilon End (Îµâ‚˜áµ¢â‚™)

```python
epsilon_end = 0.01  # Default
```

**TÄƒng lÃªn (0.02-0.05)** náº¿u:
- MÃ´i trÆ°á»ng thay Ä‘á»•i (non-stationary)
- Muá»‘n agent váº«n thÃ­ch á»©ng

**Giá»¯ tháº¥p (0.001-0.01)** náº¿u:
- MÃ´i trÆ°á»ng cá»‘ Ä‘á»‹nh
- Cáº§n performance cao nháº¥t
- Production deployment

---

### 3. Epsilon Decay Rate

```python
epsilon_decay = 0.995  # Default
```

**Decay nhanh hÆ¡n (0.99)** náº¿u:
- Ãt episodes (500-800)
- Muá»‘n há»™i tá»¥ nhanh
- Simple environment

**Decay cháº­m hÆ¡n (0.998)** náº¿u:
- Nhiá»u episodes (2000+)
- Complex environment
- Muá»‘n explore lÃ¢u hÆ¡n

---

## ğŸ’¡ Alternative Strategies

### 1. Linear Decay

```python
epsilon = epsilon_start - (epsilon_start - epsilon_end) * (ep / num_episodes)
```

**Æ¯u Ä‘iá»ƒm**: Dá»… predict, stable
**NhÆ°á»£c Ä‘iá»ƒm**: KhÃ´ng natural nhÆ° exponential

---

### 2. Step Decay

```python
if ep < 300:
    epsilon = 0.3
elif ep < 600:
    epsilon = 0.1
else:
    epsilon = 0.01
```

**Æ¯u Ä‘iá»ƒm**: RÃµ rÃ ng tá»«ng giai Ä‘oáº¡n
**NhÆ°á»£c Ä‘iá»ƒm**: Sudden jumps, khÃ´ng smooth

---

### 3. Adaptive Epsilon (Advanced)

```python
# Giáº£m epsilon khi performance tá»‘t, tÄƒng khi performance xáº¥u
if avg_cost_last_50 < best_cost_so_far:
    epsilon *= 0.99  # Giáº£m nhanh
else:
    epsilon *= 0.999  # Giáº£m cháº­m
```

**Æ¯u Ä‘iá»ƒm**: Tá»± Ä‘á»™ng thÃ­ch á»©ng
**NhÆ°á»£c Ä‘iá»ƒm**: Phá»©c táº¡p hÆ¡n

---

## ğŸ¯ Best Practices

### âœ… DOs

1. **Start high (0.3-0.5)**: KhÃ¡m phÃ¡ Ä‘áº§y Ä‘á»§ á»Ÿ Ä‘áº§u
2. **End low (0.01-0.05)**: Khai thÃ¡c tá»‘t á»Ÿ cuá»‘i
3. **Smooth decay**: DÃ¹ng exponential thay vÃ¬ step
4. **Track epsilon**: LÆ°u epsilon_history Ä‘á»ƒ visualize
5. **Test different configs**: Thá»­ nhiá»u (decay_rate, start, end)

### âŒ DON'Ts

1. âŒ Epsilon quÃ¡ tháº¥p tá»« Ä‘áº§u (< 0.1): KhÃ´ng explore Ä‘á»§
2. âŒ Epsilon quÃ¡ cao á»Ÿ cuá»‘i (> 0.1): KhÃ´ng exploit Ä‘Æ°á»£c
3. âŒ Decay quÃ¡ nhanh: Agent chÆ°a ká»‹p há»c
4. âŒ Decay quÃ¡ cháº­m: LÃ£ng phÃ­ episodes cuá»‘i
5. âŒ KhÃ´ng visualize epsilon: KhÃ´ng biáº¿t agent Ä‘ang há»c tháº¿ nÃ o

---

## ğŸ“Š Visualization Benefits

Notebook Ä‘Ã£ thÃªm 2 biá»ƒu Ä‘á»“ má»›i:

### 1. Epsilon Decay Curve
```python
plt.plot(epsilon_history)
```
â†’ Xem epsilon giáº£m nhÆ° tháº¿ nÃ o qua cÃ¡c episodes

### 2. Cost vs Epsilon Scatter
```python
plt.scatter(epsilon_history, episode_costs)
```
â†’ TÃ¬m correlation giá»¯a epsilon vÃ  performance

---

## ğŸ”¬ Experiment Ideas

### Test 1: Compare Strategies
```python
# Config 1: No decay
epsilon = 0.1 (constant)

# Config 2: Aggressive decay
epsilon_start=0.5, decay=0.99

# Config 3: Conservative decay  
epsilon_start=0.2, decay=0.998

â†’ So sÃ¡nh final cost, convergence speed
```

### Test 2: Find Optimal Decay Rate
```python
for decay_rate in [0.990, 0.995, 0.998, 0.999]:
    train_model(epsilon_decay=decay_rate)
    evaluate_and_compare()
```

### Test 3: Adaptive vs Fixed
```python
# Fixed: epsilon_decay = 0.995
# Adaptive: decay based on performance

â†’ Xem adaptive cÃ³ tá»‘t hÆ¡n khÃ´ng
```

---

## ğŸ“ˆ Expected Improvements

Vá»›i epsilon decay, báº¡n cÃ³ thá»ƒ ká»³ vá»ng:

- âœ… **Chi phÃ­ giáº£m 5-15%** so vá»›i epsilon cá»‘ Ä‘á»‹nh
- âœ… **Há»™i tá»¥ nhanh hÆ¡n 20-30%**
- âœ… **Stable hÆ¡n** á»Ÿ cuá»‘i training
- âœ… **Learning curve mÆ°á»£t mÃ  hÆ¡n**

---

## ğŸ“ TÃ³m táº¯t

| Aspect | Value | LÃ½ do |
|--------|-------|-------|
| **epsilon_start** | 0.3 | Explore nhiá»u á»Ÿ Ä‘áº§u |
| **epsilon_end** | 0.01 | Exploit tá»‘t á»Ÿ cuá»‘i |
| **epsilon_decay** | 0.995 | Giáº£m dáº§n, smooth |
| **Strategy** | Exponential | Natural, proven |
| **Tracking** | Save epsilon_history | Debug, visualize |

---

## ğŸš€ Next Steps

1. âœ… Cháº¡y training vá»›i epsilon decay
2. âœ… Xem learning curves (6 biá»ƒu Ä‘á»“)
3. âœ… So sÃ¡nh vá»›i model cÅ© (epsilon cá»‘ Ä‘á»‹nh)
4. ğŸ”¬ Thá»­ nghiá»‡m cÃ¡c decay rates khÃ¡c
5. ğŸ“Š Document káº¿t quáº£ tá»‘t nháº¥t

---

**ğŸ“š Tham kháº£o:**
- Sutton & Barto (2018): Reinforcement Learning - Chapter 2.7
- OpenAI Spinning Up: Exploration Strategies
- Deep RL Course (HuggingFace): Epsilon-Greedy

---

**âœ¨ Káº¿t luáº­n:**

Epsilon decay lÃ  má»™t **cáº£i tiáº¿n Ä‘Æ¡n giáº£n nhÆ°ng hiá»‡u quáº£ cao** cho Q-Learning. 
Thay vÃ¬ agent "mÃ¹ quÃ¡ng" explore 10% suá»‘t quÃ¡ trÃ¬nh, epsilon decay giÃºp agent:
- **Há»c nhanh hÆ¡n** á»Ÿ Ä‘áº§u (explore nhiá»u)
- **Perform tá»‘t hÆ¡n** á»Ÿ cuá»‘i (exploit nhiá»u)
- **Há»™i tá»¥ á»•n Ä‘á»‹nh hÆ¡n**

**ÄÃ£ implement trong `test2.ipynb` Cell 3 vÃ  Cell 7!** ğŸ‰
