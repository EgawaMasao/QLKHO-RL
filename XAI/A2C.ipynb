{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f457f04",
   "metadata": {},
   "source": [
    "## Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f56b8c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ tensorflow is already installed\n",
      "✓ numpy is already installed\n",
      "\n",
      "✓ All dependencies installed!\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['tensorflow', 'numpy']\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "        print(f\"✓ {package} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "        print(f\"✓ {package} installed successfully\")\n",
    "\n",
    "print(\"\\n✓ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56448cd4",
   "metadata": {},
   "source": [
    "# A2C (Advantage Actor-Critic) Algorithm\n",
    "## Reinforcement Learning for Inventory Management\n",
    "\n",
    "This notebook implements the A2C algorithm for optimizing grocery store inventory management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "656dacd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with A2C Algorithm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(edgeitems=25, linewidth=10000, precision=12, suppress=True)\n",
    "\n",
    "# Set up algorithm\n",
    "ALGORITHM = 'A2C'\n",
    "print(f\"Training with {ALGORITHM} Algorithm\")\n",
    "\n",
    "# Default FLAGS\n",
    "class FLAGS:\n",
    "    output_dir = 'C:\\\\NCKH\\\\XAI\\\\checkpoints_a2c'\n",
    "    train_file = 'data/train.tfrecords'\n",
    "    capacity_file = 'data/capacity.tfrecords'\n",
    "    stock_file = 'data/stock.tfrecords'\n",
    "    predict_file = 'data/test.tfrecords'\n",
    "    output_file = './output_a2c.csv'\n",
    "    dropout_prob = 0.1\n",
    "    train_episodes = 600\n",
    "    num_products = 220\n",
    "    num_timesteps = 900\n",
    "    num_features = 3\n",
    "    num_actions = 14\n",
    "    hidden_size = 32\n",
    "    entropy_coefficient = 0.001\n",
    "    gamma = 0.99\n",
    "    waste = 0.025\n",
    "    actor_learning_rate = 0.001\n",
    "    critic_learning_rate = 0.001\n",
    "    zero_inventory = 1e-5\n",
    "    batch_size = 32\n",
    "    action = 'TRAIN'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a996b72a",
   "metadata": {},
   "source": [
    "## Define Neural Network Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e43008b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor and Critic networks defined successfully\n"
     ]
    }
   ],
   "source": [
    "class Dense(tf.Module):\n",
    "  def __init__(self, input_dim, output_size, activation=None, stddev=1.0):\n",
    "    super(Dense, self).__init__()\n",
    "    self.w = tf.Variable(\n",
    "      tf.random.truncated_normal([input_dim, output_size], stddev=stddev), name='w')\n",
    "    self.b = tf.Variable(tf.zeros([output_size]), name='b')\n",
    "    self.activation = activation\n",
    "  def __call__(self, x):\n",
    "    y = tf.matmul(x, self.w) + self.b\n",
    "    if (self.activation):\n",
    "      y = self.activation(y)\n",
    "    return y\n",
    "\n",
    "class Actor(tf.Module):\n",
    "  def __init__(self, num_features, num_actions, hidden_size, activation=tf.nn.relu, dropout_prob=0.1):\n",
    "    super(Actor, self).__init__()\n",
    "    self.layer1 = Dense(num_features, hidden_size, activation=None)\n",
    "    self.layer2 = Dense(hidden_size, hidden_size, activation=None)\n",
    "    self.layer3 = Dense(hidden_size, hidden_size, activation=None)\n",
    "    self.layer4 = Dense(hidden_size, num_actions, activation=None)\n",
    "    self.activation = activation\n",
    "    self.dropout_prob = dropout_prob\n",
    "  def __call__(self, state):\n",
    "    layer_output = self.layer1(state)\n",
    "    layer_output = self.activation(layer_output)\n",
    "    layer_output = tf.nn.dropout(layer_output, self.dropout_prob)\n",
    "\n",
    "    layer_output = self.layer2(layer_output)\n",
    "    layer_output = self.activation(layer_output)\n",
    "    layer_output = tf.nn.dropout(layer_output, self.dropout_prob)\n",
    "\n",
    "    layer_output = self.layer3(layer_output)\n",
    "    layer_output = self.activation(layer_output)\n",
    "    layer_output = tf.nn.dropout(layer_output, self.dropout_prob)\n",
    "\n",
    "    layer_output = self.layer4(layer_output)\n",
    "    return tf.nn.softmax(layer_output)\n",
    "\n",
    "class Critic(tf.Module):\n",
    "  def __init__(self, num_features, hidden_size, activation=tf.nn.relu, dropout_prob=0.1):\n",
    "    super(Critic, self).__init__()\n",
    "    self.layer1 = Dense(num_features, hidden_size, activation=None)\n",
    "    self.layer2 = Dense(hidden_size, 1, activation=None)\n",
    "    self.activation = activation\n",
    "    self.dropout_prob = dropout_prob\n",
    "  def __call__(self, state):\n",
    "    layer_output = self.layer1(state)\n",
    "    # Layer normalization instead of GroupNormalization\n",
    "    layer_output = tf.keras.layers.LayerNormalization()(layer_output)\n",
    "    layer_output = self.activation(layer_output)\n",
    "    layer_output = tf.nn.dropout(layer_output, self.dropout_prob)\n",
    "\n",
    "    layer_output = self.layer2(layer_output)\n",
    "    return tf.squeeze(layer_output, axis=-1, name='factor_squeeze')\n",
    "\n",
    "print(\"Actor and Critic networks defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825f841e",
   "metadata": {},
   "source": [
    "## Implement Data Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28f1bbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data parsers defined successfully\n"
     ]
    }
   ],
   "source": [
    "def sales_parser(serialized_example):\n",
    "  example = tf.io.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "      \"sales\": tf.io.FixedLenFeature([FLAGS.num_products], tf.float32)\n",
    "    })\n",
    "\n",
    "  for name in list(example.keys()):\n",
    "    t = example[name]\n",
    "    if t.dtype == tf.int64:\n",
    "      t = tf.cast(t, tf.float32)\n",
    "      example[name] = t\n",
    "  return example\n",
    "\n",
    "def capacity_parser(serialized_example):\n",
    "  example = tf.io.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "      \"capacity\": tf.io.FixedLenFeature([FLAGS.num_products], tf.float32)\n",
    "    })\n",
    "\n",
    "  for name in list(example.keys()):\n",
    "    t = example[name]\n",
    "    if t.dtype == tf.int64:\n",
    "      t = tf.cast(t, tf.float32)\n",
    "      example[name] = t\n",
    "  return example\n",
    "\n",
    "def stock_parser(serialized_example):\n",
    "  example = tf.io.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "      \"stock\": tf.io.FixedLenFeature([FLAGS.num_products], tf.float32)\n",
    "    })\n",
    "\n",
    "  for name in list(example.keys()):\n",
    "    t = example[name]\n",
    "    if t.dtype == tf.int64:\n",
    "      t = tf.cast(t, tf.float32)\n",
    "      example[name] = t\n",
    "  return example\n",
    "\n",
    "print(\"Data parsers defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36dabf3",
   "metadata": {},
   "source": [
    "## Helper Functions for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49a6469e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined successfully\n"
     ]
    }
   ],
   "source": [
    "def waste(x):\n",
    "   return FLAGS.waste * x\n",
    "\n",
    "def quantile(x, q):\n",
    "  return np.quantile(x, q)\n",
    "\n",
    "def cross_entropy(p, q):\n",
    "  return -tf.reduce_mean(tf.reduce_sum(p*tf.math.log(tf.math.maximum(1e-15, q)), axis=1))\n",
    "\n",
    "print(\"Helper functions defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce1b1d",
   "metadata": {},
   "source": [
    "## Training Loop with A2C Algorithm\n",
    "\n",
    "The A2C algorithm uses:\n",
    "- actor_loss = -log(π(a|s)) * advantage - entropy_coefficient * entropy\n",
    "- critic_loss = 0.5 * (advantage)^2\n",
    "- advantage = reward + γ*V(s') - V(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cc9178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "class TrainingLogger:\n",
    "    def __init__(self, log_dir='./logA2C'):\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.log_dir = log_dir\n",
    "        self.timestamp = timestamp\n",
    "        self.metrics = defaultdict(list)\n",
    "        self.episode_logs = []\n",
    "        \n",
    "    def log_step(self, global_step, experience_step, rewards, stockouts, waste_val, delta, critic_loss, entropy_adj, actor_loss):\n",
    "        \"\"\"Log metrics for each training step\"\"\"\n",
    "        self.metrics['global_step'].append(int(global_step))\n",
    "        self.metrics['experience_step'].append(int(experience_step))\n",
    "        self.metrics['rewards'].append(float(rewards))\n",
    "        self.metrics['stockouts'].append(float(stockouts))\n",
    "        self.metrics['waste'].append(float(waste_val))\n",
    "        self.metrics['delta'].append(float(delta))\n",
    "        self.metrics['critic_loss'].append(float(critic_loss))\n",
    "        self.metrics['entropy_adjusted'].append(float(entropy_adj))\n",
    "        self.metrics['actor_loss'].append(float(actor_loss))\n",
    "        \n",
    "    def save_episode_logs(self, episode):\n",
    "        \"\"\"Save logs for each episode\"\"\"\n",
    "        if not self.metrics or len(self.metrics['global_step']) == 0:\n",
    "            return None, None\n",
    "        \n",
    "        # Create episode-specific filenames\n",
    "        json_file = os.path.join(self.log_dir, f'training_log_{self.timestamp}_episode_{episode:04d}.json')\n",
    "        csv_file = os.path.join(self.log_dir, f'training_log_{self.timestamp}_episode_{episode:04d}.csv')\n",
    "        \n",
    "        # Save as JSON\n",
    "        with open(json_file, 'w') as f:\n",
    "            json.dump(dict(self.metrics), f, indent=2)\n",
    "        \n",
    "        # Save as CSV\n",
    "        if self.metrics:\n",
    "            keys = list(self.metrics.keys())\n",
    "            with open(csv_file, 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(keys)\n",
    "                for i in range(len(self.metrics[keys[0]])):\n",
    "                    writer.writerow([self.metrics[k][i] for k in keys])\n",
    "        \n",
    "        # Store episode summary\n",
    "        episode_summary = {\n",
    "            'episode': episode,\n",
    "            'steps': len(self.metrics['global_step']),\n",
    "            'rewards_mean': float(np.mean(self.metrics['rewards'])),\n",
    "            'rewards_std': float(np.std(self.metrics['rewards'])),\n",
    "            'stockouts_mean': float(np.mean(self.metrics['stockouts'])),\n",
    "            'waste_mean': float(np.mean(self.metrics['waste'])),\n",
    "            'delta_mean': float(np.mean(self.metrics['delta'])),\n",
    "            'critic_loss_mean': float(np.mean(self.metrics['critic_loss'])),\n",
    "            'entropy_adjusted_mean': float(np.mean(self.metrics['entropy_adjusted'])),\n",
    "            'actor_loss_mean': float(np.mean(self.metrics['actor_loss']))\n",
    "        }\n",
    "        self.episode_logs.append(episode_summary)\n",
    "        \n",
    "        # Reset metrics for next episode\n",
    "        self.metrics = defaultdict(list)\n",
    "        \n",
    "        return json_file, csv_file\n",
    "    \n",
    "    def save_summary(self):\n",
    "        \"\"\"Save summary of all episodes\"\"\"\n",
    "        summary_file = os.path.join(self.log_dir, f'training_summary_{self.timestamp}.json')\n",
    "        with open(summary_file, 'w') as f:\n",
    "            json.dump(self.episode_logs, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n✓ Training summary saved: {summary_file}\")\n",
    "        return summary_file\n",
    "\n",
    "print(\"TrainingLogger class defined successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49efba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train function defined successfully\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "  # Initialize logger\n",
    "  logger = TrainingLogger(log_dir='./logA2C')\n",
    "  \n",
    "  sales_dataset = tf.data.TFRecordDataset(FLAGS.train_file).window(FLAGS.batch_size, shift=FLAGS.batch_size-1, drop_remainder=False)\n",
    "\n",
    "  capacity_dataset = tf.data.TFRecordDataset(FLAGS.capacity_file)\n",
    "  parsed_capacity_dataset = capacity_dataset.map(capacity_parser)\n",
    "  capacity = next(iter(parsed_capacity_dataset))['capacity']\n",
    "\n",
    "  actor_optimizer = tf.optimizers.Adam(FLAGS.actor_learning_rate)\n",
    "  critic_optimizer = tf.optimizers.Adam(FLAGS.critic_learning_rate)\n",
    "\n",
    "  actor = Actor(FLAGS.num_features, FLAGS.num_actions, FLAGS.hidden_size, activation=tf.nn.relu, dropout_prob=FLAGS.dropout_prob)\n",
    "  critic = Critic(FLAGS.num_features, FLAGS.hidden_size, activation=tf.nn.relu, dropout_prob=FLAGS.dropout_prob)\n",
    "\n",
    "  global_step = tf.Variable(0)\n",
    "\n",
    "  checkpoint_prefix = os.path.join(FLAGS.output_dir, \"ckpt\")\n",
    "  checkpoint = tf.train.Checkpoint(critic_optimizer=critic_optimizer, actor_optimizer=actor_optimizer, critic=critic, actor=actor, step=global_step)\n",
    "  status = checkpoint.restore(tf.train.latest_checkpoint(FLAGS.output_dir))\n",
    "\n",
    "  for episode in range(FLAGS.train_episodes):\n",
    "    x = tf.random.uniform(shape=[FLAGS.num_products], minval=0, maxval=1, dtype=tf.dtypes.float32)\n",
    "    q = waste(x)\n",
    "\n",
    "    for batch_dataset in sales_dataset:\n",
    "      with tf.GradientTape() as actor_tape, tf.GradientTape() as critic_tape:\n",
    "        experience_step = tf.constant(0)\n",
    "        experience_s = tf.TensorArray(size=FLAGS.batch_size, dtype=tf.float32, element_shape=tf.TensorShape([FLAGS.num_products, FLAGS.num_features]), name=\"experience_s\")\n",
    "        experience_u = tf.TensorArray(size=FLAGS.batch_size, dtype=tf.float32, element_shape=tf.TensorShape([FLAGS.num_products]), name=\"experience_u\")\n",
    "        experience_p = tf.TensorArray(size=FLAGS.batch_size, dtype=tf.float32, element_shape=tf.TensorShape([FLAGS.num_products, FLAGS.num_actions]), name=\"experience_p\")\n",
    "        experience_pu = tf.TensorArray(size=FLAGS.batch_size, dtype=tf.float32, element_shape=tf.TensorShape([FLAGS.num_products]), name=\"experience_pu\")\n",
    "        experience_overstock = tf.TensorArray(size=FLAGS.batch_size, dtype=tf.float32, element_shape=tf.TensorShape([FLAGS.num_products]), name=\"experience_overstock\")\n",
    "        experience_s_prime = tf.TensorArray(size=FLAGS.batch_size, dtype=tf.float32, element_shape=tf.TensorShape([FLAGS.num_products, FLAGS.num_features]), name=\"experience_s_prime\")\n",
    "        experience_r = tf.TensorArray(size=FLAGS.batch_size, dtype=tf.float32, element_shape=tf.TensorShape([FLAGS.num_products]), name=\"experience_r\")\n",
    "        experience_z = tf.TensorArray(size=FLAGS.batch_size, dtype=tf.float32, element_shape=tf.TensorShape([FLAGS.num_products]), name=\"experience_z\")\n",
    "        experience_q = tf.TensorArray(size=FLAGS.batch_size, dtype=tf.float32, element_shape=tf.TensorShape([FLAGS.num_products]), name=\"experience_q\")\n",
    "        experience_quan = tf.TensorArray(size=FLAGS.batch_size, dtype=tf.float32, element_shape=tf.TensorShape([FLAGS.num_products]), name=\"experience_quan\")\n",
    "\n",
    "        batch_iterator = batch_dataset.map(sales_parser)\n",
    "        sales = tf.divide(next(iter(batch_iterator))['sales'], capacity)\n",
    "\n",
    "        s = tf.transpose(tf.stack([x, sales, q], axis=0), perm=[1, 0])\n",
    "        policy_probs = actor(s)\n",
    "\n",
    "        for item in batch_iterator:\n",
    "          sales_prime = tf.divide(item['sales'], capacity)\n",
    "          policy_index = tf.squeeze(tf.random.categorical(tf.math.log(policy_probs), 1))\n",
    "          policy_mask = tf.one_hot(policy_index, FLAGS.num_actions)\n",
    "          policy_selected = tf.boolean_mask(policy_probs, policy_mask)\n",
    "     \n",
    "          action_space = tf.tile([[0, 0.005, 0.01, 0.0125, 0.015, 0.0175, 0.02, 0.03, 0.04, 0.08, 0.12, 0.2, 0.5, 1]], [FLAGS.num_products, 1])\n",
    "          u = tf.boolean_mask(action_space, policy_mask)\n",
    "\n",
    "          overstock = tf.math.maximum(0, (x + u) - 1)\n",
    "          x_u = tf.math.minimum(1, x + u)\n",
    "          x_prime = tf.math.maximum(0, x_u - sales)\n",
    "        \n",
    "          q_prime = waste(x_prime)\n",
    "          s_prime = tf.transpose(tf.stack([x_prime, sales_prime, q_prime], axis=0), perm=[1, 0])\n",
    "\n",
    "          z = tf.cast(x < FLAGS.zero_inventory, tf.float32)\n",
    "          quan = tf.repeat(tf.cast(quantile(x, 0.95) - quantile(x, 0.05), tf.float32), FLAGS.num_products)\n",
    "          r = tf.cast(1 - z - overstock - q - quan, tf.float32)\n",
    "\n",
    "          experience_s = experience_s.write(experience_step, s)\n",
    "          experience_u = experience_u.write(experience_step, u)\n",
    "          experience_p = experience_p.write(experience_step, policy_probs)\n",
    "          experience_pu = experience_pu.write(experience_step, policy_selected)\n",
    "          experience_overstock = experience_overstock.write(experience_step, overstock)\n",
    "          experience_s_prime = experience_s_prime.write(experience_step, s_prime)\n",
    "          experience_r = experience_r.write(experience_step, r)\n",
    "          experience_z = experience_z.write(experience_step, z)\n",
    "          experience_q = experience_q.write(experience_step, q)\n",
    "          experience_quan = experience_quan.write(experience_step, quan)\n",
    "\n",
    "          policy_probs = actor(s_prime)\n",
    "          x = x_prime\n",
    "          q = q_prime\n",
    "          s = s_prime\n",
    "          sales = sales_prime\n",
    "          experience_step = experience_step + 1\n",
    "\n",
    "        s_batch = tf.reshape(experience_s.stack()[:experience_step, :, :], [-1, FLAGS.num_features])\n",
    "        pu_batch = tf.reshape(experience_pu.stack()[:experience_step, :], [-1])\n",
    "        overstock_batch = tf.reshape(experience_overstock.stack()[:experience_step, :], [-1])\n",
    "        s_prime_batch = tf.reshape(experience_s_prime.stack()[:experience_step, :, :], [-1, FLAGS.num_features])\n",
    "        r_batch = tf.reshape(experience_r.stack()[:experience_step, :], [-1])\n",
    "        p_batch = tf.reshape(experience_p.stack()[:experience_step, :], [-1, FLAGS.num_actions])\n",
    "        z_batch = tf.reshape(experience_z.stack()[:experience_step, :], [-1])\n",
    "        q_batch = tf.reshape(experience_q.stack()[:experience_step, :], [-1])\n",
    "        quan_batch = tf.reshape(experience_quan.stack()[:experience_step, :], [-1])\n",
    "\n",
    "        # Calculate metrics\n",
    "        rewards_mean = tf.reduce_mean(r_batch, keepdims=False)\n",
    "        stockouts_mean = tf.reduce_mean(z_batch, keepdims=False)\n",
    "        waste_mean = tf.reduce_mean(q_batch, keepdims=False)\n",
    "\n",
    "        tf.print(\"rewards:\", global_step, experience_step, rewards_mean, output_stream=sys.stderr, summarize=-1)\n",
    "        tf.print(\"stockouts:\", global_step, experience_step, stockouts_mean, output_stream=sys.stderr, summarize=-1)\n",
    "        tf.print(\"waste:\", global_step, experience_step, waste_mean, output_stream=sys.stderr, summarize=-1)\n",
    "\n",
    "        v = critic(s_batch)\n",
    "        v_prime = critic(s_prime_batch)\n",
    "        y = r_batch + FLAGS.gamma*v_prime\n",
    "\n",
    "        delta = y - v\n",
    "        delta_mean = tf.reduce_mean(delta, keepdims=False)\n",
    "        tf.print(\"delta:\", global_step, delta_mean, output_stream=sys.stderr, summarize=-1)\n",
    "\n",
    "        critic_loss = 0.5*tf.reduce_mean(tf.math.square(delta), keepdims=False)\n",
    "        tf.print(\"critic loss:\", global_step, critic_loss, output_stream=sys.stderr, summarize=-1)\n",
    "\n",
    "        entropy_p = cross_entropy(p_batch, p_batch)\n",
    "        entropy_adj = FLAGS.entropy_coefficient*entropy_p\n",
    "        tf.print(\"entropy adjusted:\", global_step, entropy_adj, output_stream=sys.stderr, summarize=-1)\n",
    "\n",
    "        # A2C Algorithm\n",
    "        actor_loss = -tf.reduce_mean(tf.math.log(tf.math.maximum(1e-15, pu_batch))*tf.stop_gradient(delta), keepdims=False) - entropy_adj\n",
    "\n",
    "        tf.print(\"actor loss:\", global_step, actor_loss, output_stream=sys.stderr, summarize=-1)\n",
    "        \n",
    "        # Log metrics to file\n",
    "        logger.log_step(\n",
    "            global_step=int(global_step),\n",
    "            experience_step=int(experience_step),\n",
    "            rewards=float(rewards_mean),\n",
    "            stockouts=float(stockouts_mean),\n",
    "            waste_val=float(waste_mean),\n",
    "            delta=float(delta_mean),\n",
    "            critic_loss=float(critic_loss),\n",
    "            entropy_adj=float(entropy_adj),\n",
    "            actor_loss=float(actor_loss)\n",
    "        )\n",
    "        \n",
    "        global_step.assign_add(1)\n",
    "\n",
    "      actor_gradients = actor_tape.gradient(actor_loss, actor.variables)\n",
    "      critic_gradients = critic_tape.gradient(critic_loss, critic.variables)\n",
    "\n",
    "      actor_optimizer.apply_gradients(zip(actor_gradients, actor.variables))\n",
    "      critic_optimizer.apply_gradients(zip(critic_gradients, critic.variables))\n",
    "\n",
    "    # Save logs after each episode\n",
    "    json_file, csv_file = logger.save_episode_logs(episode + 1)\n",
    "    if (episode + 1) % 10 == 0:\n",
    "      print(f\"Episode {episode + 1} - Logs saved:\")\n",
    "      print(f\"  JSON: {json_file}\")\n",
    "      print(f\"  CSV: {csv_file}\")\n",
    "    \n",
    "    if (episode + 1) % 10 == 0:\n",
    "      checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "      print(f\"Checkpoint saved at episode {episode + 1}\")\n",
    "\n",
    "  tf.print (\"episode:\", episode, global_step, output_stream=sys.stderr, summarize=-1)\n",
    "  \n",
    "  # Save summary of all episodes\n",
    "  logger.save_summary()\n",
    "\n",
    "print(\"Train function defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143908dc",
   "metadata": {},
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67cb6ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict function defined successfully\n"
     ]
    }
   ],
   "source": [
    "def predict():\n",
    "  sales_dataset = tf.data.TFRecordDataset(FLAGS.predict_file)\n",
    "  capacity_dataset = tf.data.TFRecordDataset(FLAGS.capacity_file)\n",
    "  stock_dataset = tf.data.TFRecordDataset(FLAGS.stock_file)\n",
    "\n",
    "  parsed_capacity_dataset = capacity_dataset.map(capacity_parser)\n",
    "  capacity = next(iter(parsed_capacity_dataset))['capacity']\n",
    "\n",
    "  parsed_dataset = sales_dataset.map(sales_parser)\n",
    "\n",
    "  parsed_stock_dataset = stock_dataset.map(stock_parser)\n",
    "  x = next(iter(parsed_stock_dataset))['stock']\n",
    "\n",
    "  actor = Actor(FLAGS.num_features, FLAGS.num_actions, FLAGS.hidden_size, activation=tf.nn.relu, dropout_prob=FLAGS.dropout_prob)\n",
    "\n",
    "  checkpoint = tf.train.Checkpoint(actor=actor)\n",
    "  checkpoint.restore(tf.train.latest_checkpoint(FLAGS.output_dir)).expect_partial()\n",
    "\n",
    "  with tf.io.gfile.GFile(FLAGS.output_file, \"w\") as writer:\n",
    "    for sales_record in parsed_dataset:\n",
    "      \n",
    "      sales = tf.divide(sales_record['sales'], capacity)\n",
    "      q = waste(x)\n",
    "      s = tf.transpose(tf.stack([x, sales, q], axis=0), perm=[1, 0])\n",
    "\n",
    "      policy_probs = actor(s)\n",
    "      policy_mask = tf.one_hot(tf.math.argmax(policy_probs, axis=-1), FLAGS.num_actions)\n",
    "      action_space = tf.tile([[0, 0.005, 0.01, 0.0125, 0.015, 0.0175, 0.02, 0.03, 0.04, 0.08, 0.12, 0.2, 0.5, 1]], [FLAGS.num_products, 1])\n",
    "      u = tf.boolean_mask(action_space, policy_mask)\n",
    "\n",
    "      overstock = tf.math.maximum(0, (x + u) - 1)\n",
    "      x_u = tf.math.minimum(1, x + u)\n",
    "      stockout = tf.math.minimum(0, x_u - sales)\n",
    "\n",
    "      writer.write(\"stock:\" + ','.join(  list(map(str,   x.numpy()    ))    ) + \"\\n\")\n",
    "      writer.write(\"action:\" + ','.join(  list(map(str,   u.numpy()    ))    ) + \"\\n\")\n",
    "      writer.write(\"overstock:\" + ','.join(  list(map(str,   overstock.numpy()    ))    ) + \"\\n\")\n",
    "      writer.write(\"sales:\" + ','.join(  list(map(str,   sales.numpy()    ))    ) + \"\\n\")\n",
    "      writer.write(\"stockout:\" + ','.join(  list(map(str,   stockout.numpy()    ))    ) + \"\\n\")\n",
    "      writer.write(\"capacity:\" + ','.join(  list(map(str,   (capacity/capacity).numpy()    ))    ) + \"\\n\")\n",
    "\n",
    "      x = tf.math.maximum(0, x_u - sales)\n",
    "\n",
    "print(\"Predict function defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020954f9",
   "metadata": {},
   "source": [
    "## Execute Training or Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(FLAGS.output_dir, exist_ok=True)\n",
    "\n",
    "# Run training or prediction\n",
    "if FLAGS.action == 'TRAIN':\n",
    "    print(f\"Starting {ALGORITHM} training...\")\n",
    "    train()\n",
    "    print(f\"{ALGORITHM} training completed!\")\n",
    "elif FLAGS.action == 'PREDICT':\n",
    "    print(f\"Starting {ALGORITHM} prediction...\")\n",
    "    predict()\n",
    "    print(f\"{ALGORITHM} prediction completed! Results saved to {FLAGS.output_file}\")\n",
    "else:\n",
    "    print(f\"Unknown action: {FLAGS.action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce65f847",
   "metadata": {},
   "source": [
    "## Visualize Training Logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c15d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_episode_logs(timestamp=None, episode=None):\n",
    "    \"\"\"\n",
    "    Plot training metrics from episode log file\n",
    "    \"\"\"\n",
    "    log_dir = Path('./logA2C')\n",
    "    if not log_dir.exists():\n",
    "        print(\"No training logs found. Please run training first.\")\n",
    "        return\n",
    "    \n",
    "    # If no timestamp specified, find the latest one\n",
    "    if timestamp is None:\n",
    "        log_files = sorted(log_dir.glob('training_log_*_episode_*.json'))\n",
    "        if not log_files:\n",
    "            print(\"No episode log files found.\")\n",
    "            return\n",
    "        log_file_path = str(log_files[-1])\n",
    "    else:\n",
    "        if episode is None:\n",
    "            print(\"Please specify episode number when providing timestamp\")\n",
    "            return\n",
    "        log_file_path = str(log_dir / f'training_log_{timestamp}_episode_{episode:04d}.json')\n",
    "    \n",
    "    # Load the log file\n",
    "    try:\n",
    "        with open(log_file_path, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading log file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(metrics)\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "    fig.suptitle(f'A2C Training Metrics\\n{Path(log_file_path).name}', fontsize=16)\n",
    "    \n",
    "    # Plot each metric\n",
    "    metrics_to_plot = [\n",
    "        ('rewards', 'Rewards', axes[0, 0]),\n",
    "        ('stockouts', 'Stockouts', axes[0, 1]),\n",
    "        ('waste', 'Waste', axes[0, 2]),\n",
    "        ('delta', 'Delta (Advantage)', axes[1, 0]),\n",
    "        ('critic_loss', 'Critic Loss', axes[1, 1]),\n",
    "        ('entropy_adjusted', 'Entropy (Adjusted)', axes[1, 2]),\n",
    "        ('actor_loss', 'Actor Loss', axes[2, 0]),\n",
    "    ]\n",
    "    \n",
    "    for col, title, ax in metrics_to_plot:\n",
    "        if col in df.columns:\n",
    "            ax.plot(df[col], linewidth=1.5, alpha=0.8)\n",
    "            ax.set_title(title, fontweight='bold')\n",
    "            ax.set_xlabel('Step')\n",
    "            ax.set_ylabel('Value')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Remove extra subplots\n",
    "    axes[2, 1].remove()\n",
    "    axes[2, 2].remove()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(log_file_path.replace('.json', '_plot.png'), dpi=150, bbox_inches='tight')\n",
    "    print(f\"✓ Plot saved: {log_file_path.replace('.json', '_plot.png')}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EPISODE STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    for col in df.columns:\n",
    "        if col not in ['global_step', 'experience_step']:\n",
    "            print(f\"\\n{col.upper()}:\")\n",
    "            print(f\"  Mean:   {df[col].mean():.6f}\")\n",
    "            print(f\"  Std:    {df[col].std():.6f}\")\n",
    "            print(f\"  Min:    {df[col].min():.6f}\")\n",
    "            print(f\"  Max:    {df[col].max():.6f}\")\n",
    "\n",
    "def plot_training_summary(timestamp=None):\n",
    "    \"\"\"\n",
    "    Plot summary statistics across all episodes\n",
    "    \"\"\"\n",
    "    log_dir = Path('./logA2C')\n",
    "    if not log_dir.exists():\n",
    "        print(\"No training logs found. Please run training first.\")\n",
    "        return\n",
    "    \n",
    "    # If no timestamp specified, find the latest one\n",
    "    if timestamp is None:\n",
    "        summary_files = sorted(log_dir.glob('training_summary_*.json'))\n",
    "        if not summary_files:\n",
    "            print(\"No training summary found.\")\n",
    "            return\n",
    "        summary_file = str(summary_files[-1])\n",
    "    else:\n",
    "        summary_file = str(log_dir / f'training_summary_{timestamp}.json')\n",
    "    \n",
    "    # Load summary\n",
    "    try:\n",
    "        with open(summary_file, 'r') as f:\n",
    "            episode_logs = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading summary file: {e}\")\n",
    "        return\n",
    "    \n",
    "    df = pd.DataFrame(episode_logs)\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle(f'A2C Training Summary\\n{Path(summary_file).name}', fontsize=16)\n",
    "    \n",
    "    metrics_to_plot = [\n",
    "        ('rewards_mean', 'Avg Rewards per Episode', axes[0, 0]),\n",
    "        ('stockouts_mean', 'Avg Stockouts per Episode', axes[0, 1]),\n",
    "        ('waste_mean', 'Avg Waste per Episode', axes[0, 2]),\n",
    "        ('critic_loss_mean', 'Avg Critic Loss per Episode', axes[1, 0]),\n",
    "        ('entropy_adjusted_mean', 'Avg Entropy per Episode', axes[1, 1]),\n",
    "        ('actor_loss_mean', 'Avg Actor Loss per Episode', axes[1, 2]),\n",
    "    ]\n",
    "    \n",
    "    for col, title, ax in metrics_to_plot:\n",
    "        if col in df.columns:\n",
    "            ax.plot(df['episode'], df[col], linewidth=2, marker='o', markersize=4, alpha=0.8)\n",
    "            ax.set_title(title, fontweight='bold')\n",
    "            ax.set_xlabel('Episode')\n",
    "            ax.set_ylabel('Value')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(summary_file.replace('.json', '_plot.png'), dpi=150, bbox_inches='tight')\n",
    "    print(f\"✓ Summary plot saved: {summary_file.replace('.json', '_plot.png')}\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nTotal episodes trained: {len(df)}\")\n",
    "\n",
    "print(\"Plot functions defined successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
